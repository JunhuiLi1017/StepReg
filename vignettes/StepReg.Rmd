---
title: "StepReg: Stepwise Regression Analysis"
author:
- name: Junhui Li
  affiliation: 
  - University of Massachusset Chan medical school, Worcester, USA
- name: Kai Hu
  affiliation: University of Massachusset Chan medical school, Worcester, USA
- name: Xiaohuan Lu
  affiliation: Clark University, Worcester, USA
- name: Julie Lihua Zhu
  affiliation: University of Massachusset Chan medical school, Worcester, USA
- name: Wenxin Liu
  affiliation: China Agricultural University, Beijing, China
package: StepReg
bibliography: bibliography.bib
fontsize: 11pt
nocite: '@*'
link-citations: true
output:
  BiocStyle::html_document:
    toc_float: true
  BiocStyle::pdf_document: default
abstract: |
  A tutorial on employing StepReg for stepwise regression analysis with four well-known datasets namely the mtcars, remission, lung, and CreditCard. The guild showcases the utility of StepReg across four well-known datasets, employing it for different regression models such as linear, logistic, Cox proportional hazard, and Poisson regression. The vignette elucidates the stepwise process with distinct parameters, offering users a clear understanding of how to effectively utilize StepReg for exploratory data analysis and model building in various regression scenarios.

vignette: |
  %\VignetteIndexEntry{StepReg: Stepwise Regression made it simple}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

# Introduction

Stepwise regression is a widely employed data-mining technique aimed at identifying a valuable subset of predictors for utilization in a multiple regression model. To facilitate this process, we have developed the R package StepReg. Depending on the nature of the response variable, StepReg facilitates users in conducting linear regression for continuous outcomes, logistic regression for binary outcomes, Cox regression for time-to-event outcomes, and Poisson regression for count outcomes, incorporating popular selection criteria. It provides a versatile set of stop rules available in forward selection, backward elimination, both-direction, and best subset methods.

Here, we applied the StepReg package to four well-established and diverse datasets---mtcars, remission, lung, and CreditCard---utilizing distinct parameters across various regression scenarios. These datasets provide robust test cases for showcasing the capabilities and versatility of the StepReg package in real-world applications. Through practical demonstrations, we illustrated the application of linear stepwise regression for continuous outcomes, logistic stepwise regression for binary outcomes, Cox stepwise regression for time-to-event outcomes, and Poisson stepwise regression for count outcomes. These examples offer users valuable insights into the effective utilization of StepReg for variable selection in different regression scenarios, providing a comprehensive guide for those seeking proficiency in incorporating StepReg into their analytical toolkit.

# Features implemented in StepReg package

## Regression categories

**StepReg** supports multiple regressions, including *linear*, *logit*, *cox*, *poisson*, and *gamma* regressions. These methods primarily vary by the type of response variable (refer to the table below). Additional regression techniques can be incorporated upon user request.

```{r, echo = FALSE}
library(knitr)

Regression <- c("linear", "logit", "cox", "poisson", "gamma")
Reponse <- c("continuous", "binary", "time-to-event", "count", "time-series")
df <- data.frame(Regression, Reponse)

kable(df, caption = 'Common regression categories')
```

## Model selection

Model selection aims to identify the subset of independent variables that provide the best predictive performance for the response variable. Both stepwise regression and best subsets approaches are implemented in StepReg. For stepwise regression, there are mainly three methods: *Forward Selection*, *Backward Elimination*, *Bidirectional Elimination*.

```{r, echo = FALSE}
library(knitr)

Model_Selection <- c("Forward Selection", "Backward Elimination", "Bidirectional Elimination", "Best Subsets")
Definition <- c("In forward selection, the algorithm starts with an empty model (no predictors) and adds in variables one by one. Each step tests the addition of every possible predictor by calculating a pre-selected model fit score. Add the variable (if any) whose inclusion leads to the most statistically significant fit improvement. Repeat this process until more predictors no longer lead to a statistically better fit.",
                "In backward elimination, the algorithm starts with a full model (all predictors) and deletes variables one by one. Each step test the deletion of every possible predictor by calculating a pre-selected model fit score. Delete the variable (if any) whose loss leads to the most statistically significant fit improvement. Repeat this process until less predictors no longer lead to a statistically better fit.",
                "Bidirectional elimination is essentially a forward selection procedure combined with backward elimination at each iteration. Each iteration starts with a forward selection step that adds in predictors, followed by a round of backward elimination that removes predictors. Repeat this process until no more predictors are added or excluded.",
                "Stepwise algorithms add or delete one predictor at a time and output a single model without evaluating all candidates. Therefore, it is a relatively simple procedure that only produces one model. In contrast, the *Best Subsets* algorithm calculates all possible models and output the best-fitting models with one predictor, two predictors, etc., for users to choose from.")
df <- data.frame(Model_Selection, Definition)

kable(df, caption = 'Model selection method')
```

## Selection criterion

The *selection criterion* is another name for the aforementioned *model fit score*. It is a means of evaluating a model's quality by estimating its predictive performance. The following selection criteria have been implemented in StepReg:

To ensure formula consistency between *univariate(UMR)* and *multivariate(MMR)* multiple linear regression, additional additive and positive multiplicative constants were incorporated into the formulas of multivariate linear regression.

```{r, echo = FALSE}
library(kableExtra)
Statistic <- c(
"${n}$",
"${p}$",
"${q}$",
"$\\sigma^2$",
"${SST}$",
"${SSE}$",
"${LL}$",
"$\\text{SSE}_{\\text{det}}$",
"$\\text{SST}_{\\text{det}}$",
"${| |}$",
"$\\ln()$")

Meanings <- c(
"Sample Size",
"Number of parameters including the intercept",
"Number of dependent variables",
"Estimate of pure error variance from fitting the full model, which is the average of sigma value when it is for multivariate multiple regression",
"Total sum of squares corrected for the mean for the dependent variable, which is a numeric value for UMR and a matrix for multivariate regression",
"Error sum of squares, which is a numeric value for UMR and a matrix for multivariate regression",
"The natural logarithm of likelihood",
"The determinant of matrix ${SSE}$",
"The determinant of matrix ${SST}$",
"The absolute value",
"The natural logarithm")

kable_styling(kable(data.frame(Statistic,Meanings),format = "html", align='l', escape = F, caption = 'Statistics in Information Criterion'))
```

```{r, echo = FALSE}
library(kableExtra)
Abbreviation <- c("AIC", "AICc", "BIC", "CP", "HQ", "HQc",  "IC(1)", "IC(3/2)", "SL", "SBC", "Rsq", "adjRsq")
Definition <- c("Akaike’s information criterion",
                "Corrected Akaike’s information criterion",
                "Sawa Bayesian information criterion",
                "Mallows’ Cp statistic",
                "Hannan and Quinn information criterion",
                "Corrected Hannan and Quinn information criterion",
                "Information Criterion with Penalty Coefficient Set to 1",
                "Information Criterion with Penalty Coefficient Set to 3/2",
                "Significance Level(pvalue)",
                "Schwarz information criterion",
                "R-square statistic",
                "Adjusted R-square statistic")

Formula_in_Linear <- c("$n\\ln\\left(\\frac{|\\text{SSE}_{\\text{det}}|}{n}\\right) + 2pq + n + q(q+1)$ [@Hurvich_Tsai_1989; @Al-Subaihi_2002]",
                                 "$n\\ln\\left(\\frac{|\\text{SSE}_{\\text{det}}|}{n}\\right) + \\frac{nq(n+p)}{n-p-q-1}$ [@Hurvich_Tsai_1989; @Bedrick_Tsai_1994]",
                                 
"$n \\ln\\left(\\frac{SSE}{n}\\right) + 2(p+2)o - 2o^2, \\quad o = \\frac{n\\sigma^2}{SSE}$ [@Sawa_1978; @Judge_1985]; not available in StepReg for MMR",

"$\\frac{SSE}{\\sigma^2} + 2p - n$ [@Mallows_1973; @Hocking_1976]; Formula is available but not implemented in StepReg for MMR",

"$n\\ln\\left(\\frac{|\\text{SSE}_{\\text{det}}|}{n}\\right) + 2pq\\ln(\\ln(n))$ [@Hannan_Quinn_1979; @McQuarrie_Tsai_1998; @Hurvich_Tsai_1989]",

"$n\\ln\\left(\\frac{|\\text{SSE}_{\\text{det}}|}{n}\\right) + \\frac{2pqnln(\\ln(n))}{n-p-q-1}$ [@McQuarrie_Tsai_1998; @Hurvich_Tsai_1989]",
                              "$n\\ln\\left(\\frac{|\\text{SSE}_{\\text{det}}|}{n}\\right) + pq$ [@Nelder_Wedderburn_1972; @Smith_Spiegelhalter_1980]",
                              "$n\\ln\\left(\\frac{|\\text{SSE}_{\\text{det}}|}{n}\\right) + \\frac{3}{2}pq$ [@Smith_Spiegelhalter_1980]",

"$\\textit{F test}$ for UMR and $\\textit{Approximate F test}$ for MMR",

"$n\\ln\\left(\\frac{|\\text{SSE}_{\\text{det}}|}{n}\\right) + p \\ln(n)$ [@Hurvich_Tsai_1989; @Schwarz_1978; @Judge_1985; @Al-Subaihi_2002]",

"$1 - \\frac{SSE}{SST}$;Formula is available but not implemented in StepReg for MMR",

"$1 - \\frac{(n-1)(1-R^2)}{n-p}$ [@Darlington_1968; @Judge_1985] Formula is available but not implemented in StepReg for MMR")

Formula_in_Logit_Cox_Poisson_Gamma <- c("$-2{LL} + 2p$  [@Darlington_1968; @Judge_1985]",
                              "$-2{LL} + \\frac{n(n+p)}{n-p-2}$ [@Hurvich_Tsai_1989]",
                              "not available",
                              "not available",
                              "$-2{LL} + 2p\\ln(\\ln(n))$ [@Hannan_Quinn_1979]",
                              "$-2{LL} + \\frac{2pn \\ln(\\ln(n))}{n-p-2}$ [@McQuarrie_Tsai_1998]",
                              "$-2{LL} + p$ [@Nelder_Wedderburn_1972; @Smith_Spiegelhalter_1980]",
                              "$-2{LL} + \\frac{3}{2}p$ [@Smith_Spiegelhalter_1980]",
                              "Score Chi-square or LRT test in forward for Logistic, Poisson, and Gamma regresison; LRT test in forward for Cox; wald test in backward for Logistic, Poisson, Gamma, and Cox regression",
                              "$-2{LL} + p\\ln(n)$ [@Schwarz_1978; @Judge_1985]",
                              "not available",
                              "not available")
df <- data.frame(Abbreviation, Definition, Formula_in_Linear,Formula_in_Logit_Cox_Poisson_Gamma)

kable_styling(kable(df, format = "html", align='l', booktabs=TRUE, escape = F, caption = 'Abbreviation, Definition, and Formula of the Information Criterion for Linear, Logit, Cox, Possion and Gamma regression') %>%
  column_spec(3:4, width = "0.6in"))
```

In the literature, there is some inconsistency regarding the precise definitions of the AIC and AICC statistics. Within the context of linear regression, multiple variations of the formulas for AIC and AICC are found in statistical literature.

$AIC^1=n\ln\left(\frac{SSE}{n}\right) + 2p$[@Darlington_1968; @Judge_1985]

$AICc^1=\ln\left(\frac{SSE}{n}\right) + 1 + \frac{2(p+1)}{n-p-2}$ [@McQuarrie_Tsai_1998]

$AIC^2=AIC^1 + n + 2=n\ln\left(\frac{SSE}{n}\right) + 2p + n + 2$ [@Hurvich_Tsai_1989]

$AICc^2=n*AICc^1=n\ln\left(\frac{SSE}{n}\right) + \frac{n(p+n)}{n-p-2}$ [@Hurvich_Tsai_1989]

For a fixed number of observations, these various versions differ only by additive and positive multiplicative constants.

## Multicollinearity

This [blog](https://statisticsbyjim.com/regression/multicollinearity-in-regression-analysis/) by Jim Frost gives an excellent overview of multicollinearity and when it is necessary to remove it.

Simply put, a dataset contains multicollinearity when input predictors are correlated. When multicollinearity occurs, the interpretability of predictors will be badly affected because changes in one input variable lead to changes in other input variables. Therefore, it is hard to individually estimate the relationship between each input variable and the dependent variable.

Multicollinearity can dramatically reduce the precision of the estimated regression coefficients of correlated input variables, making it hard to find the correct model. However, as Jim pointed out, “Multicollinearity affects the coefficients and p-values, but it does not influence the predictions, precision of the predictions, and the goodness-of-fit statistics. If your primary goal is to make predictions, and you don’t need to understand the role of each independent variable, you don’t need to reduce severe multicollinearity.”

In StepReg, [QC Matrix Decomposition](https://towardsdatascience.com/qr-matrix-factorization-15bae43a6b2#:~:text=The%20QR%20matrix%20decomposition%20allows%20one%20to%20express%20a%20matrix,zero%2C%20it%20is%20also%20invertible.) is performed ahead of time to detect and remove input variables causing multicollinearity.

# StepReg Output

A list containing multiple tables will be returned. 

```{r, echo = FALSE}
library(kableExtra)
Table <- c(
"Summary of Parameters",
"Variables and Types",
"Selection Process under IC",
"Parameter Estimates")

Meanings <- c(
"The parameters utilized in stepwise regression along with their default or user-specified values",
"The variables and their respective types in the dataset",
"The detailed overview of the variable selection process under information criteria IC.",
"The parameter estimates for the optimal models under information criteria IC")

kable_styling(kable(data.frame(Table,Meanings),format = "html", align='l', escape = F, caption = 'Output Explanation of StepReg')) #%>% column_spec(1:2, width = c("2in","4in")))
```

# Recommendation of selection of variable selection method and information criteron

# Demo

A breif introduction for four datasets is descripted as below,

-   [**mtcars**](https://cran.r-project.org/web/packages/explore/vignettes/explore_mtcars.html): the mtcars dataset is a classic automotive dataset that provides information on various car models and their performance attributes. With 32 observations and 11 variables, it includes details such as miles per gallon (mpg), horsepower, and the number of cylinders.

-   [**remission**](https://online.stat.psu.edu/stat501/book/export/html/1011): the remission dataset is relevant in the context of medical research, specifically in oncology. It captures data related to the remission status of leukemia patients. The dataset includes variables such as cellularity of the marrow clot section, the highest temperature before the start of treatment, and remission status (1 for remission and 0 for non-remission).

-   [**lung**](https://stat.ethz.ch/R-manual/R-devel/library/survival/html/lung.html): the lung dataset is a dataset in the survival analysis domain, containing information related to the survival times of 228 patients with advanced lung cancer. It includes variables such as the patient's age, the type of treatment received, and survival status.

-   [**CreditCard**](https://search.r-project.org/CRAN/refmans/AER/html/CreditCard.html): the CreditCard dataset is associated with credit risk analysis and financial research. It contains information about credit card transactions, including details such as the amount spent, credit limit, and payment status.

This section provides 9 examples utilizing distinct parameters across various regression scenarios with the above 4 datasets.

## linear stepwise regression with _mtcars_

> **Example1**:  
>
> type of regression: `linear`
>
> response: `mpg`
>
> predictors: all variables except `mpg` 
>
> variable selection method: `forward` 
>
> information criteria: `AIC` 
>
> force `disp` and `cyl` to be included in all models.

```{r}
    library(StepReg)
    data(mtcars)
    formula <- mpg ~ .
    exam1 <- stepwise(formula = formula,
                      data = mtcars,
                      type = "linear",
                      include = c("disp","cyl"),
                      strategy = "forward",
                      metric = "AIC")
    exam1
```

> Visulization of the selection process under `AIC`.

```{r plot_exam1, warning=FALSE}
    plot(exam1)
```

> **Example2**: 
>
> type of regression: `linear`
>
> response: `mpg` 
>
> predictors: all other variables except `mpg` and `intercept`. 
>
> variable selection method: `bidirectional` 
>
> information criterion: run `AIC`, `AICc`, `BIC`,`HQ`, `HQc`, `SBC`, and `SL` parallelly, and the significance levels for entry (`sle`) and stay (`sls`) were both set to 0.05 . 
>
> Users can compare output within each metic through the output table and visualization.

```{r}
    formula <- mpg ~ . + 0
    exam2 <- stepwise(formula = formula,
                      data = mtcars,
                      type = "linear",
                      strategy = "bidirection",
                      metric = c("AIC","SBC","SL","AICc","BIC","HQ","HQc"),
                      sle = 0.05,
                      sls = 0.05)
    exam2
```

> Visulization of the selection process using `bidirection` strategy under information criteron `AIC`, `AICc`, `BIC`,`HQ`, `HQc`, `SBC`, and `SL` with `sle`=0.05 and `sls`=0.05. 

```{r plot_exam2, warning=FALSE}
    plot(exam2)
```

> **Example3**: 
>
> type of regression: `linear`
>
> response: multivariates of `mpg` and `drat` 
>
> predictors: `cyl`, `disp`, `hp`, `wt`, `vs`, `am` and `intercept`. 
>
> variable selection method: `subset` 
>
> information criterion: run `AIC`, `SBC` and `HQ` parallelly

```{r}
    formula <- cbind(mpg,drat) ~ cyl + disp + hp + wt + vs + am
    exam3 <- stepwise(formula = formula,
                      data = mtcars,
                      type = "linear",
                      include = 'wt',
                      strategy = "subset",
                      metric = c("AIC","AICc","SBC","HQ"),
                      best_n = 3)
    exam3
```

> Visulization of the selection process using `subset` strategy under information criteron `AIC`, `SBC` and `HQ`.

```{r plot_exam3, warning=FALSE}
    plot(exam3)
```

## Logistic stepwise regression with `remission`

> **Example4**: 
>
> type of regression: `logit`
>
> response: `remiss` 
>
> predictors: all variables except `remiss`
>
> variable selection method: `forward` 
>
> information criterion: run `AIC` and `SL` parallelly, where `sle` and `sls` were both set to 0.05.
>
> force `cell` always in the model.

```{r warning = FALSE}
    data(remission)
    formula <- remiss ~ .
    exma4 <- stepwise(formula = formula,
                      data = remission,
                      type = "logit",
                      include= "cell",
                      strategy = "forward",
                      metric = c("AIC","SL"),
                      sle = 0.05)
    exma4
```

> Visulization of the selection process using `forward` strategy under information criteron `AIC` and `SL`.

```{r plot_exam4, warning=FALSE}
    plot(exma4)
```

> **Example5**: 
>
> type of regression: `logit`
>
> response: `remiss` 
>
> predictors: all variables except `remiss`
>
> variable selection method: `subset` 
>
> information criterion: run `SBC` and `SL` parallelly, where `sle` and `sls` used default 0.15.

```{r warning = FALSE}
    data(remission)
    formula <- remiss ~ .
    exma5 <- stepwise(formula = formula,
                      data = remission,
                      type = "logit",
                      strategy = "subset",
                      metric = c("SBC","SL"),
                      best_n = 3)
    exma5
```

> Visulization of the selection process using `subset` strategy under information criteron `SBC` and `SL`.

```{r plot_exam5, warning=FALSE}
    plot(exma5)
```

## Cox stepwise regression with `lung`

> **Example6**: 
>
> type of regression: `cox`
>
> response: `Surv(time, status_binary)`
>
> predictors: all variables except `status`
>
> variable selection method: `forward` 
>
> information criterion: run `IC(1)` and `SL` parallelly, where `sle` was set to 0.05.
>
> force `age` in all models.

```{r warning = FALSE}
    lung <- survival::lung
    lung_noNA <- na.omit(lung)
    lung_noNA$status_binary <- ifelse(lung_noNA$status == 2,1,0)
    formula  =  Surv(time, status_binary) ~ . - status
    
    exma6 <- stepwise(formula = formula,
                      data = lung_noNA,
                      type = "cox",
                      include = "age",
                      strategy = "forward",
                      metric = c("IC(1)","SL"),
                      sle = 0.05)
    exma6
```

> Visulization of the selection process using `forward` strategy under information criteron `IC(1)` and `SL`.

```{r plot_exam6, warning=FALSE}
    plot(exma6)
```

> **Example7**: 
>
> type of regression: `cox`
>
> response: `Surv(time, status_binary)`
>
> predictors: all variables except `status`
>
> variable selection method: `backward` 
>
> information criterion: run `SL` and `AIC` parallelly, where `sls` was set to 0.05.

```{r warning = FALSE}
    formula = Surv(time, status_binary) ~ . - status 
    exma7 <- stepwise(formula = formula,
                      data = lung_noNA,
                      type = "cox",
                      strategy = "backward",
                      metric = c("SL","AIC"),
                      sls = 0.05)
    exma7
```

> Visulization of the selection process using `backward` strategy under information criteron `AIC` and `SL`.

```{r plot_exam7, warning=FALSE}
    plot(exma7)
```

## Poisson stepwise regression with `CreditCard`

> **Example8**: 
>
> type of regression: `poisson`
>
> response: `reports`
>
> predictors: all variables except `reports`
>
> variable selection method: `forward` 
>
> information criterion: run `SL` and `IC(3/2)` parallelly, and `sle` was set to 0.05.

```{r warning = FALSE}
    data(CreditCard, package = 'AER')
    formula  = reports ~ .
    
    exma8 <- stepwise(formula = formula,
                      data = CreditCard,
                      type = "poisson",
                      strategy = "forward",
                      metric = c("SL","IC(3/2)"),
                      sle=0.05)
    exma8
```

> Visulization of the selection process using `forward` strategy under information criteron `IC(3/2)` and `SL`.

```{r plot_exam8, warning=FALSE}
    plot(exma8)
```

> **Example9**: 
>
> type of regression: `poisson`
>
> response: `reports`
>
> predictors: all variables except `reports`
>
> variable selection method: `bidirection` 
>
> information criterion: run `AIC` and `IC(3/2)` parallelly
>
> force `card` and `months` in all models.

```{r warning = FALSE}
    formula = reports ~ .
    exma9 <- stepwise(formula = formula,
                      data = CreditCard,
                      type = "poisson",
                      include=c("card","months"),
                      strategy = "bidirection",
                      metric = c("IC(3/2)","AIC")
                      )
    exma9
```

> Visulization of the selection process using `bidirection` strategy under information criteron `IC(3/2)` and `AIC`.

```{r plot_exam9, warning=FALSE}
    plot(exma9)
```

# Session Info

```{r sessionInfo, echo = FALSE}
sessionInfo()
```
